{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvm6femgWyvBTQiusuHc/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saisrikanthrayavarapu/PySpark/blob/master/Machine_Learning_With_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "sM2vrzImKRvv"
      },
      "outputs": [],
      "source": [
        "# innstall java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.3.0-bin-hadoop3.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "\n",
        "!pip install -q pyspark\n",
        "\n",
        "# https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set your spark folder to your system path environment. \n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "mG5eo93JKf2A"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# Test the spark \n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "\n",
        "df.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjmRVJkXKqa1",
        "outputId": "8037dbba-b495-4b0d-c6b1-5f23cbb0c3a4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check PySpark version\n",
        "import pyspark\n",
        "print(pyspark.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZozVJieMqDI",
        "outputId": "8cc6f57f-070f-4a2d-cad0-6c43632868bb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize numeric data\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.linalg import Vectors\n",
        "# Create some dummy feature data\n",
        "features_df = spark.createDataFrame([\n",
        "    (1, Vectors.dense([10.0,10000.0,1.0]),),\n",
        "    (2, Vectors.dense([20.0,30000.0,2.0]),),\n",
        "    (3, Vectors.dense([30.0,40000.0,3.0]),),\n",
        "    \n",
        "],[\"id\", \"features\"] )\n",
        "features_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT1LHQOcNIfj",
        "outputId": "d10f180f-261e-4af2-a2c0-25880e33271b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+\n",
            "| id|          features|\n",
            "+---+------------------+\n",
            "|  1|[10.0,10000.0,1.0]|\n",
            "|  2|[20.0,30000.0,2.0]|\n",
            "|  3|[30.0,40000.0,3.0]|\n",
            "+---+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply MinMaxScaler transformation\n",
        "features_scaler = MinMaxScaler(inputCol = \"features\", outputCol = \"sfeatures\")\n",
        "smodel = features_scaler.fit(features_df)\n",
        "sfeatures_df = smodel.transform(features_df)\n",
        "sfeatures_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw-W2znIPziw",
        "outputId": "60a35bda-6e1e-4fec-920e-c62805cf5422"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+--------------------+\n",
            "| id|          features|           sfeatures|\n",
            "+---+------------------+--------------------+\n",
            "|  1|[10.0,10000.0,1.0]|           (3,[],[])|\n",
            "|  2|[20.0,30000.0,2.0]|[0.5,0.6666666666...|\n",
            "|  3|[30.0,40000.0,3.0]|       [1.0,1.0,1.0]|\n",
            "+---+------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# standardize numeric data\n",
        "from pyspark.ml.feature import  StandardScaler\n",
        "from pyspark.ml.linalg import Vectors\n",
        "# Create the dummy data\n",
        "features_df = spark.createDataFrame([\n",
        "    (1, Vectors.dense([10.0,10000.0,1.0]),),\n",
        "    (2, Vectors.dense([20.0,30000.0,2.0]),),\n",
        "    (3, Vectors.dense([30.0,40000.0,3.0]),),\n",
        "    \n",
        "],[\"id\", \"features\"] )\n",
        "# Apply the StandardScaler model\n",
        "features_stand_scaler = StandardScaler(inputCol = \"features\", outputCol = \"sfeatures\", withStd=True, withMean=True)\n",
        "stmodel = features_stand_scaler.fit(features_df)\n",
        "stand_sfeatures_df = stmodel.transform(features_df)\n",
        "stand_sfeatures_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0e3uX1GQC0i",
        "outputId": "574c1feb-51c9-49c4-8c6b-eb1c8e266740"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+--------------------+\n",
            "| id|          features|           sfeatures|\n",
            "+---+------------------+--------------------+\n",
            "|  1|[10.0,10000.0,1.0]|[-1.0,-1.09108945...|\n",
            "|  2|[20.0,30000.0,2.0]|[0.0,0.2182178902...|\n",
            "|  3|[30.0,40000.0,3.0]|[1.0,0.8728715609...|\n",
            "+---+------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bucketize Numeric Data\n",
        "from pyspark.ml.feature import  Bucketizer\n",
        "from pyspark.ml.linalg import Vectors\n",
        "# Define the splits for buckets\n",
        "splits = [-float(\"inf\"), -10, 0.0, 10, float(\"inf\")]\n",
        "b_data = [(-800.0,), (-10.5,), (-1.7,), (0.0,), (8.2,), (90.1,)]\n",
        "b_df = spark.createDataFrame(b_data, [\"features\"])\n",
        "b_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdggZ6fzQWfZ",
        "outputId": "3064375c-0340-460a-cf69-e8195c563765"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|features|\n",
            "+--------+\n",
            "|  -800.0|\n",
            "|   -10.5|\n",
            "|    -1.7|\n",
            "|     0.0|\n",
            "|     8.2|\n",
            "|    90.1|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming data into buckets\n",
        "bucketizer = Bucketizer(splits=splits, inputCol= \"features\", outputCol=\"bfeatures\")\n",
        "bucketed_df = bucketizer.transform(b_df)\n",
        "bucketed_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSB7s4mUQlXy",
        "outputId": "1eb1b2a4-74fe-4ec3-95ec-45cdb3952533"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+\n",
            "|features|bfeatures|\n",
            "+--------+---------+\n",
            "|  -800.0|      0.0|\n",
            "|   -10.5|      0.0|\n",
            "|    -1.7|      1.0|\n",
            "|     0.0|      2.0|\n",
            "|     8.2|      2.0|\n",
            "|    90.1|      3.0|\n",
            "+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize text Data\n",
        "from pyspark.ml.feature import  Tokenizer\n",
        "sentences_df = spark.createDataFrame([\n",
        "    (1, \"This is a sample text\"),\n",
        "    (2, \"Second is an extended version of the first\"),\n",
        "    (3, \"This elobarates the sentence giving it a long form\"),\n",
        "    \n",
        "], [\"id\", \"sentences\"])\n",
        "sentences_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOftoldFQ2xr",
        "outputId": "112c75a8-2051-49a9-d41b-38493220c2c2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+\n",
            "| id|           sentences|\n",
            "+---+--------------------+\n",
            "|  1|This is a sample ...|\n",
            "|  2|Second is an exte...|\n",
            "|  3|This elobarates t...|\n",
            "+---+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing above sentences\n",
        "sent_token = Tokenizer(inputCol = \"sentences\", outputCol = \"words\")\n",
        "sent_tokenized_df = sent_token.transform(sentences_df)\n",
        "sent_tokenized_df.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5r0eOWCRm0T",
        "outputId": "3f1aab2e-35d7-4cf1-dec0-7c4a87b13777"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(id=1, sentences='This is a sample text', words=['this', 'is', 'a', 'sample', 'text']),\n",
              " Row(id=2, sentences='Second is an extended version of the first', words=['second', 'is', 'an', 'extended', 'version', 'of', 'the', 'first']),\n",
              " Row(id=3, sentences='This elobarates the sentence giving it a long form', words=['this', 'elobarates', 'the', 'sentence', 'giving', 'it', 'a', 'long', 'form'])]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying TF-IDF vectorization to above sentences\n",
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "hashingTF = HashingTF(inputCol = \"words\", outputCol = \"rawfeatures\", numFeatures = 20)\n",
        "sent_fhTF_df = hashingTF.transform(sent_tokenized_df)\n",
        "sent_fhTF_df.take(1) #TF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CxHfIx4R1CT",
        "outputId": "30ab7330-fa9b-4845-ad05-8276a68f5969"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(id=1, sentences='This is a sample text', words=['this', 'is', 'a', 'sample', 'text'], rawfeatures=SparseVector(20, {7: 1.0, 9: 3.0, 13: 1.0}))]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IDF\n",
        "idf = IDF(inputCol = \"rawfeatures\", outputCol = \"idffeatures\")\n",
        "idfModel = idf.fit(sent_fhTF_df)\n",
        "tfidf_df = idfModel.transform(sent_fhTF_df)\n",
        "tfidf_df.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57NgQ7_gSUN8",
        "outputId": "70a4dba1-726a-43ee-ca65-67174837c8d1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(id=1, sentences='This is a sample text', words=['this', 'is', 'a', 'sample', 'text'], rawfeatures=SparseVector(20, {7: 1.0, 9: 3.0, 13: 1.0}), idffeatures=SparseVector(20, {7: 0.2877, 9: 0.863, 13: 0.2877}))]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering Using PySpark\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans, BisectingKMeans\n",
        "import glob\n",
        "# Downloading the clustering dataset\n",
        "!wget -q 'https://raw.githubusercontent.com/amjadraza/blogs-data/master/spark_ml/clustering_dataset.csv'"
      ],
      "metadata": {
        "id": "_p4JDQeYShDB"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "clustering_file_name ='clustering_dataset.csv'\n",
        "import pandas as pd\n",
        "# df = pd.read_csv(clustering_file_name)\n",
        "cluster_df = spark.read.csv(clustering_file_name, header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "8d70FTVqSyuL"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coverting the input data into features column\n",
        "vectorAssembler = VectorAssembler(inputCols = ['col1', 'col2', 'col3'], outputCol = \"features\")\n",
        "vcluster_df = vectorAssembler.transform(cluster_df)\n",
        "vcluster_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9b6iCjLS3o5",
        "outputId": "d14d25a3-c9a8-44bf-e4f0-82ef86494640"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+--------------+\n",
            "|col1|col2|col3|      features|\n",
            "+----+----+----+--------------+\n",
            "|   7|   4|   1| [7.0,4.0,1.0]|\n",
            "|   7|   7|   9| [7.0,7.0,9.0]|\n",
            "|   7|   9|   6| [7.0,9.0,6.0]|\n",
            "|   1|   6|   5| [1.0,6.0,5.0]|\n",
            "|   6|   7|   7| [6.0,7.0,7.0]|\n",
            "|   7|   9|   4| [7.0,9.0,4.0]|\n",
            "|   7|  10|   6|[7.0,10.0,6.0]|\n",
            "|   7|   8|   2| [7.0,8.0,2.0]|\n",
            "|   8|   3|   8| [8.0,3.0,8.0]|\n",
            "|   4|  10|   5|[4.0,10.0,5.0]|\n",
            "+----+----+----+--------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the k-means algorithm\n",
        "kmeans = KMeans().setK(3)\n",
        "kmeans = kmeans.setSeed(1)\n",
        "kmodel = kmeans.fit(vcluster_df)\n",
        "# After training using k-means algorithm\n",
        "centers = kmodel.clusterCenters()\n",
        "print(\"The location of centers: {}\".format(centers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6AQ19LiS978",
        "outputId": "95f16d70-2011-411e-9809-914057f16150"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The location of centers: [array([35.88461538, 31.46153846, 34.42307692]), array([80.        , 79.20833333, 78.29166667]), array([5.12, 5.84, 4.84])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Hierarchical Clustering\n",
        "bkmeans = BisectingKMeans().setK(3)\n",
        "bkmeans = bkmeans.setSeed(1)\n",
        "bkmodel = bkmeans.fit(vcluster_df)\n",
        "bkcneters = bkmodel.clusterCenters()\n",
        "bkcneters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X2U01U-TK8W",
        "outputId": "41988e42-7e58-448e-9f17-0b6711c008a3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([5.12, 5.84, 4.84]),\n",
              " array([35.88461538, 31.46153846, 34.42307692]),\n",
              " array([80.        , 79.20833333, 78.29166667])]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Using PySpark\n",
        "# Downloading the clustering data\n",
        "!wget -q \"https://raw.githubusercontent.com/amjadraza/blogs-data/master/spark_ml/iris.csv\"\n",
        "df_iris = pd.read_csv(\"https://raw.githubusercontent.com/amjadraza/blogs-data/master/spark_ml/iris.csv\", header=None)\n",
        "df_iris.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jFcKdbbuTka3",
        "outputId": "b3f312c7-a3a6-4555-f8c7-4eaab061f517"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0    1    2    3            4\n",
              "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
              "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
              "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
              "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
              "4  5.0  3.6  1.4  0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88679c20-7856-4e42-bfc2-1998bf1390b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88679c20-7856-4e42-bfc2-1998bf1390b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88679c20-7856-4e42-bfc2-1998bf1390b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88679c20-7856-4e42-bfc2-1998bf1390b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the Iris Data\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import  StringIndexer\n",
        "# Read the iris data\n",
        "iris_df = spark.createDataFrame(df_iris)\n",
        "iris_df.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqZr9AWSVVIi",
        "outputId": "7eaae238-f20d-4c26-8b2a-7e77b281fb22"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+---+-----------+\n",
            "|0  |1  |2  |3  |4          |\n",
            "+---+---+---+---+-----------+\n",
            "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
            "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
            "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
            "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
            "|5.0|3.6|1.4|0.2|Iris-setosa|\n",
            "+---+---+---+---+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns\n",
        "iris_df = iris_df.select(col(\"0\").alias(\"sepal_length\"),\n",
        "                         col(\"1\").alias(\"sepal_width\"),\n",
        "                         col(\"2\").alias(\"petal_length\"),\n",
        "                         col(\"3\").alias(\"petal_width\"),\n",
        "                         col(\"4\").alias(\"species\"),\n",
        "                        )\n",
        "# Converting the columns into features\n",
        "vectorAssembler = VectorAssembler(inputCols = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
        "                                  outputCol = \"features\")\n",
        "viris_df = vectorAssembler.transform(iris_df)\n",
        "viris_df.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiBgZ8f5WlH9",
        "outputId": "b456a1fc-9d5d-4ee8-d0be-fc081787e0cd"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-----------+-----------------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species    |features         |\n",
            "+------------+-----------+------------+-----------+-----------+-----------------+\n",
            "|5.1         |3.5        |1.4         |0.2        |Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
            "|4.9         |3.0        |1.4         |0.2        |Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
            "|4.7         |3.2        |1.3         |0.2        |Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
            "|4.6         |3.1        |1.5         |0.2        |Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
            "|5.0         |3.6        |1.4         |0.2        |Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
            "+------------+-----------+------------+-----------+-----------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing and labelling\n",
        "indexer = StringIndexer(inputCol=\"species\", outputCol = \"label\")\n",
        "iviris_df = indexer.fit(viris_df).transform(viris_df)\n",
        "iviris_df.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqsk_9pSWqJU",
        "outputId": "4b2b3417-fe1a-4b82-9440-97c0dae8155f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-----------+-----------------+-----+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species    |features         |label|\n",
            "+------------+-----------+------------+-----------+-----------+-----------------+-----+\n",
            "|5.1         |3.5        |1.4         |0.2        |Iris-setosa|[5.1,3.5,1.4,0.2]|0.0  |\n",
            "|4.9         |3.0        |1.4         |0.2        |Iris-setosa|[4.9,3.0,1.4,0.2]|0.0  |\n",
            "|4.7         |3.2        |1.3         |0.2        |Iris-setosa|[4.7,3.2,1.3,0.2]|0.0  |\n",
            "|4.6         |3.1        |1.5         |0.2        |Iris-setosa|[4.6,3.1,1.5,0.2]|0.0  |\n",
            "|5.0         |3.6        |1.4         |0.2        |Iris-setosa|[5.0,3.6,1.4,0.2]|0.0  |\n",
            "+------------+-----------+------------+-----------+-----------+-----------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes Classification\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "# Create the traing and test splits\n",
        "splits = iviris_df.randomSplit([0.6,0.4], 1)\n",
        "train_df = splits[0]\n",
        "test_df = splits[1]\n",
        "# Apply the Naive bayes classifier\n",
        "nb = NaiveBayes(modelType=\"multinomial\")\n",
        "nbmodel = nb.fit(train_df)\n",
        "predictions_df = nbmodel.transform(test_df)\n",
        "predictions_df.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoyE2WVYXAdY",
        "outputId": "dd08b27c-e8d4-43a1-8396-26d1965a8901"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-----------+-----------------+-----+-------------------------------------------------------------+------------------------------------------------------------+----------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species    |features         |label|rawPrediction                                                |probability                                                 |prediction|\n",
            "+------------+-----------+------------+-----------+-----------+-----------------+-----+-------------------------------------------------------------+------------------------------------------------------------+----------+\n",
            "|4.3         |3.0        |1.1         |0.1        |Iris-setosa|[4.3,3.0,1.1,0.1]|0.0  |[-9.966434726497221,-11.29459549275882,-11.956012812323921]  |[0.7134106367667449,0.18902823898426266,0.09756112424899266]|0.0       |\n",
            "|4.5         |2.3        |1.3         |0.3        |Iris-setosa|[4.5,2.3,1.3,0.3]|0.0  |[-10.445578237339822,-11.046685172103672,-11.573240051498392]|[0.5341897676084534,0.29284522031258065,0.17296501207896584]|0.0       |\n",
            "|4.6         |3.1        |1.5         |0.2        |Iris-setosa|[4.6,3.1,1.5,0.2]|0.0  |[-11.415900336839973,-12.444796411503397,-13.082052735807258]|[0.6466740705579853,0.23112214522391455,0.1222037842181001] |0.0       |\n",
            "|4.7         |3.2        |1.3         |0.2        |Iris-setosa|[4.7,3.2,1.3,0.2]|0.0  |[-11.212186849617217,-12.453421861597786,-13.128317779966677]|[0.696280720934572,0.20124395965516112,0.10247531941026686] |0.0       |\n",
            "|4.8         |3.1        |1.6         |0.2        |Iris-setosa|[4.8,3.1,1.6,0.2]|0.0  |[-11.750846171651437,-12.743482215254547,-13.38685314121621] |[0.6388328686938338,0.23675049555564373,0.12441663575052245]|0.0       |\n",
            "+------------+-----------+------------+-----------+-----------+-----------------+-----+-------------------------------------------------------------+------------------------------------------------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the trained classifier\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "nbaccuracy = evaluator.evaluate(predictions_df)\n",
        "nbaccuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IliJmReXqXk",
        "outputId": "46906653-917f-440a-9f92-b3bab8cfdf44"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8275862068965517"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron Classification\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "# Define the MLP Classifier\n",
        "layers = [4,5,5,3]\n",
        "mlp = MultilayerPerceptronClassifier(layers = layers, seed=1)\n",
        "mlp_model = mlp.fit(train_df)\n",
        "mlp_predictions = mlp_model.transform(test_df)\n",
        "# Evaluate the MLP classifier\n",
        "mlp_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "mlp_accuracy = mlp_evaluator.evaluate(mlp_predictions)\n",
        "mlp_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kele7ay5Xwnl",
        "outputId": "d02a739a-4c19-4d30-9740-7b5e23811465"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9827586206896551"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Trees Classification\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "# Define the DT Classifier \n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "dt_model = dt.fit(train_df)\n",
        "dt_predictions = dt_model.transform(test_df)\n",
        "# Evaluate the DT Classifier\n",
        "dt_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "dt_accuracy = dt_evaluator.evaluate(dt_predictions)\n",
        "dt_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF4g48h5X5kB",
        "outputId": "6207e2e2-d923-425b-853e-04fc1e478edd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9827586206896551"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression using PySpark\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "# Read the iris data\n",
        "df_ccpp = pd.read_csv(\"https://raw.githubusercontent.com/amjadraza/blogs-data/master/spark_ml/ccpp.csv\")\n",
        "pp_df = spark.createDataFrame(df_ccpp)\n",
        "pp_df.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QobyaPE7YKlj",
        "outputId": "2e37ff51-c250-4151-f1de-754d282e026e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-------+-----+------+\n",
            "|AT   |V    |AP     |RH   |PE    |\n",
            "+-----+-----+-------+-----+------+\n",
            "|14.96|41.76|1024.07|73.17|463.26|\n",
            "|25.18|62.96|1020.04|59.08|444.37|\n",
            "|5.11 |39.4 |1012.16|92.14|488.56|\n",
            "|20.86|57.32|1010.24|76.64|446.48|\n",
            "|10.82|37.5 |1009.23|96.62|473.9 |\n",
            "+-----+-----+-------+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the feature column using VectorAssembler class\n",
        "vectorAssembler = VectorAssembler(inputCols =[\"AT\", \"V\", \"AP\", \"RH\"], outputCol = \"features\")\n",
        "vpp_df = vectorAssembler.transform(pp_df)\n",
        "vpp_df.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmseK5VIY32Q",
        "outputId": "9294ddce-c001-404a-d88c-c0cfd51109b3"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-------+-----+------+---------------------------+\n",
            "|AT   |V    |AP     |RH   |PE    |features                   |\n",
            "+-----+-----+-------+-----+------+---------------------------+\n",
            "|14.96|41.76|1024.07|73.17|463.26|[14.96,41.76,1024.07,73.17]|\n",
            "|25.18|62.96|1020.04|59.08|444.37|[25.18,62.96,1020.04,59.08]|\n",
            "|5.11 |39.4 |1012.16|92.14|488.56|[5.11,39.4,1012.16,92.14]  |\n",
            "|20.86|57.32|1010.24|76.64|446.48|[20.86,57.32,1010.24,76.64]|\n",
            "|10.82|37.5 |1009.23|96.62|473.9 |[10.82,37.5,1009.23,96.62] |\n",
            "+-----+-----+-------+-----+------+---------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "# Define and fit Linear Regression\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"PE\")\n",
        "lr_model = lr.fit(vpp_df)\n",
        "# Print and save the Model output\n",
        "print(lr_model.coefficients)\n",
        "print(lr_model.intercept)\n",
        "print(lr_model.summary.rootMeanSquaredError)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9qnUpieYa-n",
        "outputId": "8755ad96-75ab-423d-94c6-52095d66b888"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.9775131066803813,-0.23391642257631212,0.06208294371702,-0.15805410292542044]\n",
            "454.6092743812023\n",
            "4.557126016749479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Regression\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "vpp_df.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7BssTEWY_t5",
        "outputId": "45711960-411a-4e66-d0d9-ed1c1c631c28"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-------+-----+------+---------------------------+\n",
            "|AT   |V    |AP     |RH   |PE    |features                   |\n",
            "+-----+-----+-------+-----+------+---------------------------+\n",
            "|14.96|41.76|1024.07|73.17|463.26|[14.96,41.76,1024.07,73.17]|\n",
            "|25.18|62.96|1020.04|59.08|444.37|[25.18,62.96,1020.04,59.08]|\n",
            "|5.11 |39.4 |1012.16|92.14|488.56|[5.11,39.4,1012.16,92.14]  |\n",
            "|20.86|57.32|1010.24|76.64|446.48|[20.86,57.32,1010.24,76.64]|\n",
            "|10.82|37.5 |1009.23|96.62|473.9 |[10.82,37.5,1009.23,96.62] |\n",
            "+-----+-----+-------+-----+------+---------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define train and test data split\n",
        "splits = vpp_df.randomSplit([0.7,0.3])\n",
        "train_df = splits[0]\n",
        "test_df = splits[1]\n",
        "# Define the Decision Tree Model \n",
        "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"PE\")\n",
        "dt_model = dt.fit(train_df)\n",
        "dt_predictions = dt_model.transform(test_df)\n",
        "dt_predictions.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arquR34vZMmg",
        "outputId": "85c34333-5edf-467b-b5b7-0b12d16da7a2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-------+-----+------+--------------------------+------------------+\n",
            "|AT  |V    |AP     |RH   |PE    |features                  |prediction        |\n",
            "+----+-----+-------+-----+------+--------------------------+------------------+\n",
            "|3.26|41.31|996.32 |100.0|489.38|[3.26,41.31,996.32,100.0] |486.09122641509447|\n",
            "|3.38|39.64|1011.0 |81.22|488.92|[3.38,39.64,1011.0,81.22] |486.09122641509447|\n",
            "|3.6 |35.19|1018.73|99.1 |488.98|[3.6,35.19,1018.73,99.1]  |486.09122641509447|\n",
            "|3.82|35.47|1016.62|84.34|489.04|[3.82,35.47,1016.62,84.34]|486.09122641509447|\n",
            "|3.91|35.47|1016.92|86.03|488.67|[3.91,35.47,1016.92,86.03]|486.09122641509447|\n",
            "+----+-----+-------+-----+------+--------------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting Decision Tree Regression\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "# Define the GBT Model\n",
        "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"PE\")\n",
        "gbt_model = gbt.fit(train_df)\n",
        "gbt_predictions = gbt_model.transform(test_df)\n",
        "# Evaluate the GBT Model\n",
        "gbt_evaluator = RegressionEvaluator(labelCol=\"PE\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "gbt_rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
        "print(\"The RMSE of GBT Tree regression Model is {}\".format(gbt_rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbXV7vKgZtZc",
        "outputId": "8ec7c376-68d1-48c7-bf6d-ac30476e6941"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The RMSE of GBT Tree regression Model is 3.979736047466769\n"
          ]
        }
      ]
    }
  ]
}